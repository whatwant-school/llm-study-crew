{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Tokenization"
      ],
      "metadata": {
        "id": "QP_rSGa-DVhU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsuqEaYTDLYw",
        "outputId": "3af2f1c4-b1b4-4b89-edc2-256bd33ca9ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "king    : 0\n",
            "queen   : 1\n",
            "man     : 2\n",
            "woman   : 3\n",
            "apple   : 4\n",
            "orange  : 5\n",
            "fruit   : 6\n",
            "dog     : 7\n",
            "cat     : 8\n",
            "animal  : 9\n"
          ]
        }
      ],
      "source": [
        "vocab = ['king', 'queen', 'man', 'woman', 'apple', 'orange', 'fruit', 'dog', 'cat', 'animal']\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "# 각 단어와 인덱스를 출력\n",
        "for word, idx in word_to_idx.items():\n",
        "    print(f\"{word:8}: {idx}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Embedding"
      ],
      "metadata": {
        "id": "wkMDBGDVmG3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "embedding_dim = 5\n",
        "embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "\n",
        "for word, idx in word_to_idx.items():\n",
        "    vector = embedding.weight[idx]\n",
        "    print(f\"{word:8} (index {idx}): {vector.tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g78bdV0nDbyA",
        "outputId": "336738a4-dee4-4669-d0e9-79a9f5fa0468"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "king     (index 0): [-0.9843325614929199, 1.1391586065292358, -0.9179290533065796, 0.7631993889808655, 0.1090579703450203]\n",
            "queen    (index 1): [0.6273496747016907, 1.3188352584838867, -0.328174889087677, -0.24093422293663025, 0.7450929284095764]\n",
            "man      (index 2): [1.5874661207199097, -0.984518826007843, -1.4914472103118896, 0.8793133497238159, -0.8942144513130188]\n",
            "woman    (index 3): [-0.5352128148078918, -0.47506096959114075, -0.9547194242477417, 0.2387956827878952, -0.7360312938690186]\n",
            "apple    (index 4): [0.6903787851333618, 1.5064266920089722, -1.8485966920852661, -1.1875098943710327, -0.8520223498344421]\n",
            "orange   (index 5): [0.9441819190979004, 0.0930686667561531, -0.14445760846138, 1.0427806377410889, 0.7968577146530151]\n",
            "fruit    (index 6): [2.117994785308838, -0.38488301634788513, 1.0496927499771118, 0.09504067152738571, -0.1869911551475525]\n",
            "dog      (index 7): [0.6117108464241028, 0.8869150280952454, -0.6443786025047302, 1.357578992843628, -0.044430434703826904]\n",
            "cat      (index 8): [0.28429731726646423, 1.3037093877792358, -0.1464586853981018, 0.4657917320728302, 0.45096224546432495]\n",
            "animal   (index 9): [1.6972694396972656, 0.3640768229961395, -0.8536919355392456, 1.6457747220993042, -0.28551527857780457]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Cosine Similarity"
      ],
      "metadata": {
        "id": "W24hziIvqs7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    return F.cosine_similarity(vec1, vec2).item()"
      ],
      "metadata": {
        "id": "dD2Cr4sbqnAi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 기준 단어 설정\n",
        "base_word = 'king'\n",
        "base_idx = torch.tensor([word_to_idx[base_word]], dtype=torch.long)\n",
        "base_vec = embedding(base_idx)\n",
        "\n",
        "# 다른 단어들과의 유사도 계산\n",
        "print(f\"\\n'{base_word}'와 다른 단어들의 유사도:\")\n",
        "for word in vocab:\n",
        "    if word == base_word:\n",
        "        continue\n",
        "    idx = torch.tensor([word_to_idx[word]], dtype=torch.long)\n",
        "    vec = embedding(idx)\n",
        "    sim = cosine_similarity(base_vec, vec)\n",
        "    print(f\"{word:8}: {sim:>7.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_BfWWqIq2PJ",
        "outputId": "7174c396-bf1a-4ce3-edee-43cb681d502a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'king'와 다른 단어들의 유사도:\n",
            "queen   :  0.3333\n",
            "man     : -0.1427\n",
            "woman   :  0.3522\n",
            "apple   :  0.3128\n",
            "orange  :  0.0614\n",
            "fruit   : -0.7424\n",
            "dog     :  0.5706\n",
            "cat     :  0.6080\n",
            "animal  :  0.1530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training"
      ],
      "metadata": {
        "id": "C9DVhrIbpWZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# 학습 설정\n",
        "optimizer = optim.SGD(embedding.parameters(), lr=0.01)\n",
        "loss_fn = nn.CosineEmbeddingLoss()\n",
        "\n",
        "# 간단한 학습 데이터 (임의의 유사성 쌍)\n",
        "pairs = [\n",
        "    ('king', 'queen'),\n",
        "    ('king', 'man'),\n",
        "    ('queen', 'woman'),\n",
        "    ('man', 'woman'),\n",
        "    ('apple', 'orange'),\n",
        "    ('dog', 'cat'),\n",
        "    ('fruit', 'apple'),\n",
        "    ('fruit', 'orange'),\n",
        "    ('animal', 'dog'),\n",
        "    ('animal', 'cat')\n",
        "]\n",
        "\n",
        "for epoch in range(500):\n",
        "    total_loss = 0\n",
        "    for w1, w2 in pairs:\n",
        "        idx1 = torch.tensor([word_to_idx[w1]], dtype=torch.long)\n",
        "        idx2 = torch.tensor([word_to_idx[w2]], dtype=torch.long)\n",
        "        vec1 = embedding(idx1)\n",
        "        vec2 = embedding(idx2)\n",
        "        target = torch.tensor([1.0])  # 유사한 단어는 1.0\n",
        "        loss = loss_fn(vec1, vec2, target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch+1:4}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIBm_iSko1xm",
        "outputId": "0c2a2771-e5f8-453d-92e1-c72e4a7f29a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   20, Loss: 6.6738\n",
            "Epoch   40, Loss: 5.7269\n",
            "Epoch   60, Loss: 4.8702\n",
            "Epoch   80, Loss: 4.1160\n",
            "Epoch  100, Loss: 3.4666\n",
            "Epoch  120, Loss: 2.9158\n",
            "Epoch  140, Loss: 2.4524\n",
            "Epoch  160, Loss: 2.0638\n",
            "Epoch  180, Loss: 1.7380\n",
            "Epoch  200, Loss: 1.4645\n",
            "Epoch  220, Loss: 1.2344\n",
            "Epoch  240, Loss: 1.0406\n",
            "Epoch  260, Loss: 0.8772\n",
            "Epoch  280, Loss: 0.7394\n",
            "Epoch  300, Loss: 0.6231\n",
            "Epoch  320, Loss: 0.5250\n",
            "Epoch  340, Loss: 0.4422\n",
            "Epoch  360, Loss: 0.3724\n",
            "Epoch  380, Loss: 0.3136\n",
            "Epoch  400, Loss: 0.2640\n",
            "Epoch  420, Loss: 0.2222\n",
            "Epoch  440, Loss: 0.1870\n",
            "Epoch  460, Loss: 0.1574\n",
            "Epoch  480, Loss: 0.1325\n",
            "Epoch  500, Loss: 0.1115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기준 단어 설정\n",
        "base_word = 'king'\n",
        "base_idx = torch.tensor([word_to_idx[base_word]], dtype=torch.long)\n",
        "base_vec = embedding(base_idx)\n",
        "\n",
        "# 다른 단어들과의 유사도 계산\n",
        "print(f\"\\n'{base_word}'와 다른 단어들의 유사도:\")\n",
        "for word in vocab:\n",
        "    if word == base_word:\n",
        "        continue\n",
        "    idx = torch.tensor([word_to_idx[word]], dtype=torch.long)\n",
        "    vec = embedding(idx)\n",
        "    sim = cosine_similarity(base_vec, vec)\n",
        "    print(f\"{word:8}: {sim:>7.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wV1N7tqqIHV",
        "outputId": "4dac5d8c-97c4-47fc-a4b2-efea086a45a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'king'와 다른 단어들의 유사도:\n",
            "queen   :  0.9988\n",
            "man     :  0.9706\n",
            "woman   :  0.9947\n",
            "apple   :  0.5313\n",
            "orange  :  0.4586\n",
            "fruit   :  0.3885\n",
            "dog     :  0.7412\n",
            "cat     :  0.7405\n",
            "animal  :  0.7401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4jrlFrECrg4D"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}